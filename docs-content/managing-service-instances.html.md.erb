---
title: Managing Service Instances
owner: Spring Cloud Services
---

<strong><%= modified_date %></strong>

See below for information about managing Data Flow service instances using the Cloud Foundry Command Line Interface tool (cf CLI). You can also manage Data Flow service instances using <%= vars.scdf_platform_name %> Apps Manager.

## <a id="creating"></a>Creating an Instance

<p class='note'><strong>Important</strong>: If you are using the <a href="https://network.pivotal.io/products/p-redis/">Redis for PCF</a> product for the Spring Cloud Data Flow analytics store, you cannot create more Data Flow service instances than the setting of the Redis product's Service Instance Limit (the default Service Instance Limit for Redis for PCF is 5). See the <a href="https://docs.pivotal.io/redis/installing.html#shared-vm-config">Shared-VM Plan</a> section of the <a href="https://docs.pivotal.io/redis/installing.html">Installing and Upgrading Redis for PCF</a> topic in the <a href="https://docs.pivotal.io/redis/">Redis for PCF documentation</a> for information about configuring this limit.</p>

Begin by targeting the correct org and space.

<%= partial vars.scdf_managing_instances_target %>

You can view plan details for the Data Flow product using `cf marketplace -s`.

<%= partial vars.scdf_managing_instances_marketplace %>

### <a id="setting-the-buildpack"></a>Setting the Buildpack

Each Data Flow service instance can be given the name of a buildpack to use for deploying stream and task apps. You can set the buildpack for the service instance using a `buildpack` parameter given to `cf create-service`. To create a service instance that uses a buildpack named `custom-java-buildpack` to deploy apps, you might run:

<pre class="terminal">
$ cf create-service p-dataflow standard data-flow -c '{"buildpack": "custom-java-buildpack"}'
</pre>

### <a id="setting-dependent-services"></a>Setting Dependent Services
 
Each Data Flow service instance uses three dependent data services. Defaults for these services can be configured in the tile settings, and these defaults can be overridden for each individual service instance at create time.

<p class='note'><strong>Note</strong>: The service offerings with the plan <code>proxy</code> are proxy services used by Spring Cloud Data Flow for PCF service instances. The Spring Cloud Data Flow service broker creates and deletes instances of these services automatically along with each Spring Cloud Data Flow service instance. Do not manually create or delete instances of these services.</p>

General parameters used to configure dependent data services for a Data Flow service instance are listed below.

| Parameter                                 | Function                                                                                                               |
|-------------------------------------------|------------------------------------------------------------------------------------------------------------------------|
| <code>relational-data-service.name</code> | The name of the service to use for a relational database that stores Spring Cloud Data Flow metadata and task history. |
| <code>relational-data-service.plan</code> | The name of the service plan to use for the relational database service.                                               |
| <code>messaging-data-service.name</code>  | The name of the service to use for a RabbitMQ or Kafka server that facilitates event messaging.                        |
| <code>messaging-data-service.plan</code>  | The name of the service plan to use for the RabbitMQ or Kafka service.                                                 |
| <code>analytics-data-service.name</code>  | The name of the service to use for a Redis server that stores analytics.                                               |
| <code>analytics-data-service.plan</code>  | The name of the service plan to use for the Redis server.                                                              |
| <code>skipper-relational.name</code>      | The name of the service to use for a relational database used by the Skipper application.                              |
| <code>skipper-relational.plan</code>      | The name of the service plan to use for a relational database used by the Skipper application.                         |

### <a id="setting-maven-properties"></a>Setting Maven Properties

Each Data Flow service instance can optionally specify Maven configuration properties. For the complete list of properties that can be specified, see the ["Maven" section in the OSS Spring Cloud Data Flow documentation](https://docs.spring.io/spring-cloud-dataflow/docs/1.5.0.RELEASE/reference/htmlsingle/#configuration-maven).

Maven configuration properties can be set for each Data Flow service instance using parameters given to `cf create-service`. To set the `maven.remote-repositories.repo1.url` property, you might use a command such as the following:

<pre class="terminal">
$ cf create-service p-dataflow standard data-flow -c '{"maven.remote-repositories.repo1.url": "https://repo.spring.io/libs-snapshot"}'
</pre>

### <a id="creating-the-instance"></a>Creating the Instance

Create the service instance using `cf create-service`. To create a Data Flow service that uses a Redis Cloud service available from your PCF marketplace and sets the Maven `maven.remote-repositories.repo1.url` property to `https://repo.spring.io/release`, you might run:

<%= partial vars.scdf_managing_instances_create %>

As the command output suggests, you can use the `cf services` or `cf service` commands to check the status of the service instance. When the service instance is ready, the `cf service` command will give a status of `create succeeded`:

<%= partial vars.scdf_managing_instances_service %>

## <a id="upgrading"></a>Upgrading an Instance

After an upgrade of the Spring Cloud Data Flow for PCF product, you can use the `cf update-service` command to upgrade individual Data Flow service instances.

Begin by targeting the correct org and space.

<%= partial vars.scdf_managing_instances_target %>

You can view all service instances in the space using `cf services`.

<%= partial vars.scdf_managing_instances_services %>

Upgrade the Data Flow service instance using `cf update-service`, passing the `-c` flag to set the `upgrade` parameter to `true`.

<%= partial vars.scdf_managing_instances_upgrade %>

As the output from the `cf update-service` command suggests, you can use the `cf services` or `cf service` commands to check the status of the service instance. When the Data Flow service instance has been upgraded, the `cf service` command will give a status of `update succeeded`:

<%= partial vars.scdf_managing_instances_upgrade_finished %>

## <a id="deleting"></a>Deleting an Instance

Deleting a Data Flow service instance will result in deletion of all of its dependent service instances.

Begin by targeting the correct org and space.

<%= partial vars.scdf_managing_instances_target %>

You can view all service instances in the space using `cf services`.

<%= partial vars.scdf_managing_instances_services %>

Delete the Data Flow service instance using `cf delete-service`. When prompted, enter `y` to confirm the deletion.

<%= partial vars.scdf_managing_instances_delete %>

The dependent service instances for the Data Flow server service instance are deleted first, and then the Data Flow server service instance itself is deleted.

As the output from the `cf delete-service` command suggests, you can use the `cf services` or `cf service` commands to check the status of the service instance. When the Data Flow service instance and its dependent service instances have been deleted, the `cf services` command will no longer list the service instance:

<%= partial vars.scdf_managing_instances_delete_finished %>
